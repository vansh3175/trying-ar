<!DOCTYPE html>
<html>
<head>
  <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
  <style>
    /* Pulsing cursor that responds to surfaces */
    #cursor {
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }
    
    /* Debug panel */
    #debug {
      position: fixed;
      top: 10px;
      left: 10px;
      background: rgba(0,0,0,0.7);
      color: white;
      padding: 10px;
      font-family: monospace;
      z-index: 10000;
      border-radius: 5px;
    }
  </style>
</head>
<body>
  <a-scene 
    embedded 
    arjs="sourceType: webcam; trackingMethod: best; debugUIEnabled: true"
    vr-mode-ui="enabled: false"
    renderer="logarithmicDepthBuffer: true;"
  >
    <!-- Surface-detecting cursor -->
    <a-entity id="cursor"
      cursor="rayOrigin: mouse; fuse: false"
      raycaster="objects: [data-ar-surface]; far: 20; interval: 100"
      geometry="primitive: ring; radiusInner: 0.015; radiusOuter: 0.02"
      material="color: #FFAA00; shader: flat; opacity: 0.8"
      position="0 0 -0.5"
      data-ar-surface
    ></a-entity>

    <!-- Plant model -->
    <a-entity id="plant"
      gltf-model="url(./plant.glb)"
      scale="0.3 0.3 0.3"
      visible="false"
      shadow
    ></a-entity>

    <a-entity camera></a-entity>
  </a-scene>

  <div id="debug">Initializing AR - move your phone slowly...</div>

  <script>
    const scene = document.querySelector('a-scene');
    const cursor = document.getElementById('cursor');
    const plant = document.getElementById('plant');
    const debugEl = document.getElementById('debug');
    
    // 1. WAIT FOR SCENE TO LOAD
    scene.addEventListener('loaded', () => {
      debugEl.textContent = "Scan surfaces - point at textured areas";
      
      // 2. CONFIGURE RAYCASTER PROPERLY
      const raycaster = cursor.components.raycaster;
      raycaster.far = 10; // meters
      raycaster.showLine = true;
      raycaster.lineColor = 'red';
      
      // 3. SURFACE DETECTION FEEDBACK
      raycaster.el.addEventListener('raycaster-intersection', (e) => {
        cursor.setAttribute('material', 'color', '#00FF00'); // Green when surface found
        debugEl.textContent = "âœ… Surface detected - tap to place plant";
      });
      
      raycaster.el.addEventListener('raycaster-intersection-cleared', (e) => {
        cursor.setAttribute('material', 'color', '#FFAA00'); // Orange when no surface
        debugEl.textContent = "âš ï¸ Move to a textured surface";
      });
      
      // 4. CLICK HANDLER WITH VISUAL FEEDBACK
      cursor.addEventListener('click', (e) => {
        if (!e.detail.intersection) {
          cursor.setAttribute('animation', 'property: material.color; to: red; dur: 200; easing: linear');
          setTimeout(() => cursor.setAttribute('material', 'color', '#FFAA00'), 300);
          return;
        }
        
        // Place plant at intersection point
        plant.setAttribute('position', e.detail.intersection.point);
        plant.setAttribute('visible', 'true');
        
        // Visual confirmation
        cursor.setAttribute('animation', 'property: material.color; to: #00FFFF; dur: 200; easing: linear');
        setTimeout(() => cursor.setAttribute('material', 'color', '#00FF00'), 300);
        
        debugEl.innerHTML = `ðŸŒ± Plant placed!<br>
                           X: ${e.detail.intersection.point.x.toFixed(2)}<br>
                           Y: ${e.detail.intersection.point.y.toFixed(2)}<br>
                           Z: ${e.detail.intersection.point.z.toFixed(2)}`;
      });
    });
  </script>
</body>
</html>